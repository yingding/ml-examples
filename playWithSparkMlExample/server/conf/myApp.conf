##
## This file needs to referenced by the shell variable CONFIG
##
##
## String shall be used without the space and quotes
app.tcp.seed=seedToChange
##
## Daemon Conf
##
## false / true
app.exampleDaemon.isActivated=false
app.exampleDaemon.delay=10
## InSeconds = every minutes
app.exampleDaemon.executionInterval=60

## Spark ML config
# shall the spark ml module be activated
# false / true
app.spark.isActivated=true
# Spark Cluster Session Config Path
# app.spark.configPath=/

# spark work lives in bridge Network Container, which can only communicate with gateway
# CASE 1: mongodb container is in the same docker bridge network as spark cluster, use the -link name of mongodb container
# CASE 2: mongodb container is outside the bridge network of spark cluster, use the IP address of mongodb container
# Notice: In CASE 2 "127.0.0.1", "Gateway IP of bridge network", "host.docker.internal" will all NOT work.
app.spark.mongoHost=yourHostIp
app.spark.mongoPort=27017
app.spark.mongoUser=xxx
app.spark.mongoPW=yyy
app.spark.mongoIsReplicaSet=false
# Not used any more
# https://stackoverflow.com/questions/43417216/spark-submit-packages-is-not-working-on-my-cluster-what-could-be-the-reason
app.spark.jarsPackages=mongo-spark-connector_2.12






